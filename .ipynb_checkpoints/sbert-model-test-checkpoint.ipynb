{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38608fde-b081-4baa-ba15-b246ef020743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "\n",
    "def ensure_output_dir(output_dir):\n",
    "    \"\"\"Create output directory if it doesn't exist\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "def plot_roc_curves(y_true, y_pred, labels, output_dir):\n",
    "    \"\"\"Plot ROC curves for each class\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        fpr, tpr, _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.plot(\n",
    "            fpr, \n",
    "            tpr, \n",
    "            label=f'{label} (AUC = {roc_auc:.2f})'\n",
    "        )\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'roc_curves.png'))\n",
    "    plt.close()\n",
    "    \n",
    "class MetricTracker:\n",
    "    def __init__(self):\n",
    "        self.metrics = defaultdict(list)\n",
    "    \n",
    "    def update(self, metrics_dict):\n",
    "        for key, value in metrics_dict.items():\n",
    "            self.metrics[key].append(value)\n",
    "    \n",
    "    def get_metric(self, metric_name):\n",
    "        return self.metrics[metric_name]\n",
    "\n",
    "def plot_training_history(tracker, fold, output_dir):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(tracker.get_metric('train_loss'), label='Train Loss')\n",
    "    plt.plot(tracker.get_metric('val_loss'), label='Validation Loss')\n",
    "    plt.title(f'Loss History - Fold {fold}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracies\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(tracker.get_metric('exact_match_accuracy'), label='Exact Match')\n",
    "    plt.plot(tracker.get_metric('hamming_accuracy'), label='Hamming')\n",
    "    plt.title(f'Accuracy History - Fold {fold}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot F1, Precision, Recall\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(tracker.get_metric('f1'), label='F1')\n",
    "    plt.plot(tracker.get_metric('precision'), label='Precision')\n",
    "    plt.plot(tracker.get_metric('recall'), label='Recall')\n",
    "    plt.title(f'Metrics History - Fold {fold}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'training_history_fold_{fold}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "def plot_confusion_matrices(y_true, y_pred, labels, output_dir):\n",
    "    \"\"\"Plot confusion matrix for each class\"\"\"\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    n_classes = len(labels)\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, label in enumerate(labels):\n",
    "        cm = confusion_matrix(y_true[:, idx], y_pred_binary[:, idx])\n",
    "        sns.heatmap(cm, annot=True, fmt='d', ax=axes[idx])\n",
    "        axes[idx].set_title(f'Confusion Matrix - {label}')\n",
    "        axes[idx].set_xlabel('Predicted')\n",
    "        axes[idx].set_ylabel('True')\n",
    "    \n",
    "    if len(labels) < len(axes):\n",
    "        for idx in range(len(labels), len(axes)):\n",
    "            fig.delaxes(axes[idx])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'confusion_matrices.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_label_distribution(train_labels, test_labels, labels, output_dir):\n",
    "    \"\"\"Plot label distribution in train and test sets\"\"\"\n",
    "    train_dist = train_labels.sum(axis=0)\n",
    "    test_dist = test_labels.sum(axis=0)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, train_dist, width, label='Train')\n",
    "    plt.bar(x + width/2, test_dist, width, label='Test')\n",
    "    \n",
    "    plt.xlabel('Labels')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Label Distribution in Train and Test Sets')\n",
    "    plt.xticks(x, labels, rotation=45)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'label_distribution.png'))\n",
    "    plt.close()\n",
    "\n",
    "def create_performance_tables(y_true, y_pred, labels, output_dir):\n",
    "    \"\"\"Create and save detailed performance tables\"\"\"\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    metrics_dict = {\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1-Score': [],\n",
    "        'Support': []\n",
    "    }\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(\n",
    "            y_true[:, i], y_pred_binary[:, i], average='binary'\n",
    "        )\n",
    "        metrics_dict['Precision'].append(precision)\n",
    "        metrics_dict['Recall'].append(recall)\n",
    "        metrics_dict['F1-Score'].append(f1)\n",
    "        metrics_dict['Support'].append(support)\n",
    "    \n",
    "    df_metrics = pd.DataFrame(metrics_dict, index=labels)\n",
    "    df_metrics.to_csv(os.path.join(output_dir, 'class_performance_metrics.csv'))\n",
    "    \n",
    "    corr_matrix = np.corrcoef(y_pred_binary.T)\n",
    "    df_corr = pd.DataFrame(corr_matrix, index=labels, columns=labels)\n",
    "    df_corr.to_csv(os.path.join(output_dir, 'prediction_correlations.csv'))\n",
    "    \n",
    "    return df_metrics, df_corr\n",
    "\n",
    "def plot_metric_comparison(fold_metrics):\n",
    "    \"\"\"Plot comparison of metrics across folds\"\"\"\n",
    "    metrics = ['exact_match_accuracy', 'hamming_accuracy', 'f1', 'precision', 'recall']\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    data = []\n",
    "    for metric in metrics:\n",
    "        data.append([metrics_dict[metric] for metrics_dict in fold_metrics])\n",
    "    \n",
    "    plt.boxplot(data, labels=metrics)\n",
    "    plt.title('Metric Distribution Across Folds')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fold_metrics_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "class DocumentProcessor:\n",
    "    def __init__(self, model_name):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.labels = ['Treatment', 'Prevention', 'Diagnosis', 'Mechanism', \n",
    "                      'Transmission', 'Epidemic Forecasting', 'Case Report']\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        text = str(text).lower()\n",
    "        text = ' '.join(text.split())\n",
    "        return text\n",
    "    \n",
    "    def process_labels(self, label_text):\n",
    "        label_list = label_text.split(';')\n",
    "        label_array = np.zeros(len(self.labels))\n",
    "        for label in label_list:\n",
    "            if label in self.labels:\n",
    "                label_array[self.labels.index(label)] = 1\n",
    "        return label_array\n",
    "    \n",
    "    def generate_embeddings(self, texts, batch_size=32, cache_file=None):\n",
    "        if cache_file and os.path.exists(cache_file):\n",
    "            print(f\"Loading cached embeddings from {cache_file}\")\n",
    "            with open(cache_file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        \n",
    "        print(\"Generating new embeddings...\")\n",
    "        embeddings = []\n",
    "        for i in tqdm(range(0, len(texts), batch_size)):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            batch_embeddings = self.model.encode(batch_texts)\n",
    "            embeddings.extend(batch_embeddings)\n",
    "        \n",
    "        embeddings = np.array(embeddings)\n",
    "        \n",
    "        if cache_file:\n",
    "            print(f\"Caching embeddings to {cache_file}\")\n",
    "            with open(cache_file, 'wb') as f:\n",
    "                pickle.dump(embeddings, f)\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "class COVIDDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = torch.FloatTensor(embeddings)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "\n",
    "class TopicClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1=512, hidden_dim2=256, num_classes=7):\n",
    "        super(TopicClassifier, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.layer2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.layer3 = nn.Linear(hidden_dim2, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.layer3(x))\n",
    "        return x\n",
    "\n",
    "# Modify train_fold function to use MetricTracker\n",
    "def train_fold(model, train_loader, val_loader, criterion, optimizer, device, fold, output_dir):\n",
    "    model = model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "    \n",
    "    tracker = MetricTracker()\n",
    "    \n",
    "    for epoch in range(20):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_embeddings, batch_labels in tqdm(train_loader, desc=f'Fold {fold}, Epoch {epoch+1} - Training'):\n",
    "            batch_embeddings = batch_embeddings.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_embeddings)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_metrics = evaluate_fold(model, val_loader, criterion, device, fold)\n",
    "        \n",
    "        avg_train_loss = train_loss/len(train_loader)\n",
    "        \n",
    "        # Track metrics\n",
    "        tracker.update({\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            **val_metrics\n",
    "        })\n",
    "        \n",
    "        print(f'Fold {fold}, Epoch {epoch+1}')\n",
    "        print(f'Training Loss: {avg_train_loss:.4f}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        print('Validation Metrics:')\n",
    "        print(f'  Exact Match Accuracy: {val_metrics[\"exact_match_accuracy\"]:.4f}')\n",
    "        print(f'  Hamming Accuracy: {val_metrics[\"hamming_accuracy\"]:.4f}')\n",
    "        print(f'  F1: {val_metrics[\"f1\"]:.4f}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), os.path.join(output_dir, f'best_model_fold_{fold}.pt'))\n",
    "\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Plot training history for this fold\n",
    "    plot_training_history(tracker, fold, output_dir)\n",
    "    return best_val_loss, val_metrics\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, labels):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_embeddings, batch_labels in tqdm(test_loader, desc='Testing'):\n",
    "            batch_embeddings = batch_embeddings.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            outputs = model(batch_embeddings)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            predictions = outputs.cpu().numpy()\n",
    "            all_predictions.extend(predictions)\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "    \n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Calculate and print all metrics\n",
    "    overall_metrics, per_category_metrics = calculate_overall_metrics(\n",
    "        all_labels, all_predictions, labels\n",
    "    )\n",
    "    \n",
    "    return test_loss/len(test_loader), all_predictions, all_labels, overall_metrics, per_category_metrics\n",
    "\n",
    "\n",
    "def plot_metrics_heatmap(metrics_dict, labels, output_dir):\n",
    "    \"\"\"Create a heatmap of metrics for each category\"\"\"\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Precision': metrics_dict['Precision'],\n",
    "        'Recall': metrics_dict['Recall'],\n",
    "        'F1-Score': metrics_dict['F1-Score']\n",
    "    }, index=labels)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(metrics_df, annot=True, cmap='YlOrRd', fmt='.3f')\n",
    "    plt.title('Performance Metrics by Category')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'metrics_heatmap.png'))\n",
    "    plt.close()\n",
    "    \n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate various metrics for multi-label classification\"\"\"\n",
    "    # Convert predictions to binary\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    # Exact match accuracy (all labels must match)\n",
    "    exact_match_accuracy = np.mean(np.all(y_pred_binary == y_true, axis=1))\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    per_class_accuracy = np.mean(y_pred_binary == y_true, axis=0)\n",
    "    \n",
    "    # Hamming accuracy (proportion of correct predictions)\n",
    "    hamming_accuracy = np.mean(y_pred_binary == y_true)\n",
    "    \n",
    "    # Calculate precision, recall, f1\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred_binary, average='samples'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'exact_match_accuracy': exact_match_accuracy,\n",
    "        'hamming_accuracy': hamming_accuracy,\n",
    "        'per_class_accuracy': per_class_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "def calculate_overall_metrics(y_true, y_pred, labels):\n",
    "    \"\"\"\n",
    "    Calculate both overall and per-category metrics\n",
    "    \"\"\"\n",
    "    # Convert predictions to binary\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    # Per-category metrics\n",
    "    per_category_metrics = {\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1-Score': [],\n",
    "        'Support': []\n",
    "    }\n",
    "    \n",
    "    print(\"\\nPer-category Metrics:\")\n",
    "    print(\"--------------------\")\n",
    "    for i, label in enumerate(labels):\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(\n",
    "            y_true[:, i], y_pred_binary[:, i], average='binary'\n",
    "        )\n",
    "        per_category_metrics['Precision'].append(precision)\n",
    "        per_category_metrics['Recall'].append(recall)\n",
    "        per_category_metrics['F1-Score'].append(f1)\n",
    "        per_category_metrics['Support'].append(support)\n",
    "        \n",
    "        print(f\"\\n{label}:\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "        print(f\"Support: {support}\")\n",
    "    \n",
    "    # Overall metrics (micro average)\n",
    "    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred_binary, average='micro'\n",
    "    )\n",
    "    \n",
    "    # Overall metrics (macro average)\n",
    "    macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred_binary, average='macro'\n",
    "    )\n",
    "    \n",
    "    # Overall metrics (weighted average)\n",
    "    weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred_binary, average='weighted'\n",
    "    )\n",
    "    \n",
    "    # Exact match ratio (perfect predictions across all categories)\n",
    "    exact_match = np.mean(np.all(y_pred_binary == y_true, axis=1))\n",
    "    \n",
    "    # Hamming accuracy (percentage of correct labels)\n",
    "    hamming_accuracy = np.mean(y_pred_binary == y_true)\n",
    "    \n",
    "    # Create summary dictionary\n",
    "    overall_metrics = {\n",
    "        'Micro-average': {\n",
    "            'Precision': micro_precision,\n",
    "            'Recall': micro_recall,\n",
    "            'F1-Score': micro_f1\n",
    "        },\n",
    "        'Macro-average': {\n",
    "            'Precision': macro_precision,\n",
    "            'Recall': macro_recall,\n",
    "            'F1-Score': macro_f1\n",
    "        },\n",
    "        'Weighted-average': {\n",
    "            'Precision': weighted_precision,\n",
    "            'Recall': weighted_recall,\n",
    "            'F1-Score': weighted_f1\n",
    "        },\n",
    "        'Exact Match Ratio': exact_match,\n",
    "        'Hamming Accuracy': hamming_accuracy\n",
    "    }\n",
    "    \n",
    "    # Create and display summary DataFrame\n",
    "    df_overall = pd.DataFrame({\n",
    "        'Metric': ['Precision', 'Recall', 'F1-Score'],\n",
    "        'Micro-avg': [micro_precision, micro_recall, micro_f1],\n",
    "        'Macro-avg': [macro_precision, macro_recall, macro_f1],\n",
    "        'Weighted-avg': [weighted_precision, weighted_recall, weighted_f1]\n",
    "    }).set_index('Metric')\n",
    "    \n",
    "    print(\"\\nOverall Metrics:\")\n",
    "    print(\"--------------\")\n",
    "    print(f\"\\nExact Match Ratio: {exact_match:.4f}\")\n",
    "    print(f\"Hamming Accuracy: {hamming_accuracy:.4f}\")\n",
    "    print(\"\\nAveraged Metrics:\")\n",
    "    print(df_overall)\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    df_overall.to_csv('overall_metrics.csv')\n",
    "    df_categories = pd.DataFrame(per_category_metrics, index=labels)\n",
    "    df_categories.to_csv('per_category_metrics.csv')\n",
    "    \n",
    "    return overall_metrics, per_category_metrics\n",
    "\n",
    "def evaluate_fold(model, val_loader, criterion, device, fold):\n",
    "    \"\"\"Evaluate model on validation set during training\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_embeddings, batch_labels in val_loader:\n",
    "            batch_embeddings = batch_embeddings.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            outputs = model(batch_embeddings)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            predictions = outputs.cpu().numpy()\n",
    "            all_predictions.extend(predictions)\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Calculate metrics with binary predictions\n",
    "    metrics = calculate_metrics(all_labels, all_predictions)\n",
    "    \n",
    "    return val_loss/len(val_loader), metrics\n",
    "\n",
    "def run(model_name='all-mpnet-base-v2'):\n",
    "    output_dir = 'output/sbert'\n",
    "    ensure_output_dir(output_dir)\n",
    "    fold_metrics = []\n",
    "    \n",
    "    # Load datasets\n",
    "    print(\"Loading datasets...\")\n",
    "    train_df = pd.read_csv('./dataset/BC7-LitCovid-Train.csv')\n",
    "    test_df = pd.read_csv('./dataset/BC7-LitCovid-Dev.csv')  # Using dev set as test set\n",
    "    \n",
    "    # Initialize processor\n",
    "    processor = DocumentProcessor(model_name)\n",
    "    \n",
    "    # Process all data\n",
    "    print(\"Processing training data...\")\n",
    "    train_abstracts = train_df['abstract'].apply(processor.clean_text).values\n",
    "    train_labels = np.array([processor.process_labels(label) for label in train_df['label']])\n",
    "    train_embeddings = processor.generate_embeddings(train_abstracts, cache_file='train_embeddings_cache.pkl')\n",
    "    \n",
    "    # Get the actual embedding dimension\n",
    "    embedding_dim = train_embeddings.shape[1]\n",
    "    print(f\"Training embeddings shape: {train_embeddings.shape}\")\n",
    "    print(f\"Detected embedding dimension: {embedding_dim}\")\n",
    "    \n",
    "    print(\"Processing test data...\")\n",
    "    test_abstracts = test_df['abstract'].apply(processor.clean_text).values\n",
    "    test_labels = np.array([processor.process_labels(label) for label in test_df['label']])\n",
    "    test_embeddings = processor.generate_embeddings(test_abstracts, cache_file='test_embeddings_cache.pkl')\n",
    "    print(f\"Test embeddings shape: {test_embeddings.shape}\")\n",
    "    \n",
    "    # Verify dimensions match\n",
    "    if train_embeddings.shape[1] != test_embeddings.shape[1]:\n",
    "        raise ValueError(f\"Embedding dimensions don't match! Train: {train_embeddings.shape[1]}, Test: {test_embeddings.shape[1]}\")\n",
    "    \n",
    "    # Create full datasets\n",
    "    train_dataset = COVIDDataset(train_embeddings, train_labels)\n",
    "    test_dataset = COVIDDataset(test_embeddings, test_labels)\n",
    "    \n",
    "    # Let's verify the dimensions of our dataset outputs\n",
    "    sample_batch = next(iter(DataLoader(train_dataset, batch_size=1)))\n",
    "    print(f\"Sample batch embedding shape: {sample_batch[0].shape}\")\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "    \n",
    "    # Setup for k-fold cross validation\n",
    "    k_folds = 5\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # For storing fold results\n",
    "    fold_results = []  # Store validation losses\n",
    "    fold_metrics = []  # Store other metrics\n",
    "    best_val_loss = float('inf')\n",
    "    best_fold = 0\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # K-fold Cross Validation\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(train_dataset)):\n",
    "        print(f'\\nFOLD {fold+1}/{k_folds}')\n",
    "        \n",
    "        train_subsampler = SubsetRandomSampler(train_ids)\n",
    "        val_subsampler = SubsetRandomSampler(val_ids)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_subsampler)\n",
    "        val_loader = DataLoader(train_dataset, batch_size=32, sampler=val_subsampler)\n",
    "        \n",
    "        # Initialize model with correct input dimension\n",
    "        model = TopicClassifier(input_dim=embedding_dim)\n",
    "        if fold == 0:\n",
    "            model_config = {\n",
    "                'input_dim': embedding_dim,\n",
    "                'state_dict_keys': list(model.state_dict().keys())\n",
    "            }\n",
    "            print(f\"Model configuration: {model_config}\")\n",
    "        \n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        val_loss, final_metrics = train_fold(model, train_loader, val_loader, criterion, optimizer, device, fold+1, output_dir)\n",
    "        fold_results.append(val_loss)\n",
    "        fold_metrics.append(final_metrics)\n",
    "        \n",
    "        # Track best fold\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_fold = fold\n",
    "\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    model = TopicClassifier(input_dim=embedding_dim)\n",
    "    # Use the tracked best_fold instead of computing it\n",
    "    model.load_state_dict(torch.load(f'best_model_fold_{best_fold+1}.pt'))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    test_loss, test_predictions, test_labels, overall_metrics, per_category_metrics = evaluate_model(\n",
    "        model, test_loader, criterion, device, processor.labels\n",
    "    )\n",
    "    \n",
    "    # Create visualizations\n",
    "    plot_confusion_matrices(test_labels, test_predictions, processor.labels, output_dir)\n",
    "    plot_roc_curves(test_labels, test_predictions, processor.labels, output_dir)\n",
    "    plot_metrics_heatmap(per_category_metrics, processor.labels, output_dir)\n",
    "    \n",
    "    # Save all metrics to a summary file\n",
    "    with open(os.path.join(output_dir, 'metrics_summary.txt'), 'w') as f:\n",
    "        f.write(\"Overall Metrics:\\n\")\n",
    "        f.write(\"---------------\\n\")\n",
    "        for metric_type, metrics in overall_metrics.items():\n",
    "            f.write(f\"\\n{metric_type}:\\n\")\n",
    "            if isinstance(metrics, dict):\n",
    "                for name, value in metrics.items():\n",
    "                    f.write(f\"{name}: {value:.4f}\\n\")\n",
    "            else:\n",
    "                f.write(f\"{metrics:.4f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3e0f61c-4f95-4cc6-adf0-aa382ee82e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n",
      "Generating new embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [01:28<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching embeddings to train_embeddings_cache.pkl\n",
      "Training embeddings shape: (24960, 768)\n",
      "Detected embedding dimension: 768\n",
      "Processing test data...\n",
      "Generating new embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:20<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching embeddings to test_embeddings_cache.pkl\n",
      "Test embeddings shape: (6239, 768)\n",
      "Sample batch embedding shape: torch.Size([1, 768])\n",
      "Using device: cuda\n",
      "\n",
      "FOLD 1/5\n",
      "Model configuration: {'input_dim': 768, 'state_dict_keys': ['layer1.weight', 'layer1.bias', 'layer2.weight', 'layer2.bias', 'layer3.weight', 'layer3.bias']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 1 - Training: 100%|██████████| 624/624 [00:05<00:00, 121.46it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 1\n",
      "Training Loss: 0.2020\n",
      "Validation Loss: 0.1491\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7196\n",
      "  Hamming Accuracy: 0.9424\n",
      "  F1: 0.8587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 2 - Training: 100%|██████████| 624/624 [00:00<00:00, 785.58it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 2\n",
      "Training Loss: 0.1448\n",
      "Validation Loss: 0.1389\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7388\n",
      "  Hamming Accuracy: 0.9469\n",
      "  F1: 0.8677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 3 - Training: 100%|██████████| 624/624 [00:00<00:00, 678.59it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 3\n",
      "Training Loss: 0.1343\n",
      "Validation Loss: 0.1298\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7512\n",
      "  Hamming Accuracy: 0.9500\n",
      "  F1: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 4 - Training: 100%|██████████| 624/624 [00:00<00:00, 735.34it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 4\n",
      "Training Loss: 0.1274\n",
      "Validation Loss: 0.1282\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7584\n",
      "  Hamming Accuracy: 0.9506\n",
      "  F1: 0.8770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 5 - Training: 100%|██████████| 624/624 [00:00<00:00, 865.09it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 5\n",
      "Training Loss: 0.1223\n",
      "Validation Loss: 0.1292\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7528\n",
      "  Hamming Accuracy: 0.9508\n",
      "  F1: 0.8803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 6 - Training: 100%|██████████| 624/624 [00:00<00:00, 1025.51it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 6\n",
      "Training Loss: 0.1187\n",
      "Validation Loss: 0.1262\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7576\n",
      "  Hamming Accuracy: 0.9515\n",
      "  F1: 0.8820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 7 - Training: 100%|██████████| 624/624 [00:00<00:00, 869.67it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 7\n",
      "Training Loss: 0.1133\n",
      "Validation Loss: 0.1267\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7560\n",
      "  Hamming Accuracy: 0.9514\n",
      "  F1: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 8 - Training: 100%|██████████| 624/624 [00:00<00:00, 741.40it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 8\n",
      "Training Loss: 0.1091\n",
      "Validation Loss: 0.1289\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7486\n",
      "  Hamming Accuracy: 0.9493\n",
      "  F1: 0.8804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 9 - Training: 100%|██████████| 624/624 [00:00<00:00, 960.18it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 9\n",
      "Training Loss: 0.1052\n",
      "Validation Loss: 0.1310\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7552\n",
      "  Hamming Accuracy: 0.9508\n",
      "  F1: 0.8811\n",
      "Early stopping triggered at epoch 9\n",
      "\n",
      "FOLD 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 1 - Training: 100%|██████████| 624/624 [00:00<00:00, 853.44it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 1\n",
      "Training Loss: 0.2024\n",
      "Validation Loss: 0.1471\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7188\n",
      "  Hamming Accuracy: 0.9416\n",
      "  F1: 0.8502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 2 - Training: 100%|██████████| 624/624 [00:00<00:00, 937.10it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 2\n",
      "Training Loss: 0.1448\n",
      "Validation Loss: 0.1366\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7334\n",
      "  Hamming Accuracy: 0.9449\n",
      "  F1: 0.8643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 3 - Training: 100%|██████████| 624/624 [00:00<00:00, 820.74it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 3\n",
      "Training Loss: 0.1342\n",
      "Validation Loss: 0.1338\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7372\n",
      "  Hamming Accuracy: 0.9460\n",
      "  F1: 0.8670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 4 - Training: 100%|██████████| 624/624 [00:00<00:00, 1015.67it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 4\n",
      "Training Loss: 0.1270\n",
      "Validation Loss: 0.1321\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7374\n",
      "  Hamming Accuracy: 0.9464\n",
      "  F1: 0.8668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 5 - Training: 100%|██████████| 624/624 [00:00<00:00, 862.80it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 5\n",
      "Training Loss: 0.1214\n",
      "Validation Loss: 0.1305\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7492\n",
      "  Hamming Accuracy: 0.9479\n",
      "  F1: 0.8706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 6 - Training: 100%|██████████| 624/624 [00:00<00:00, 822.67it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 6\n",
      "Training Loss: 0.1170\n",
      "Validation Loss: 0.1299\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7436\n",
      "  Hamming Accuracy: 0.9475\n",
      "  F1: 0.8716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 7 - Training: 100%|██████████| 624/624 [00:00<00:00, 661.64it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 7\n",
      "Training Loss: 0.1125\n",
      "Validation Loss: 0.1303\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7486\n",
      "  Hamming Accuracy: 0.9485\n",
      "  F1: 0.8761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 8 - Training: 100%|██████████| 624/624 [00:00<00:00, 992.31it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 8\n",
      "Training Loss: 0.1088\n",
      "Validation Loss: 0.1322\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7452\n",
      "  Hamming Accuracy: 0.9475\n",
      "  F1: 0.8734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 9 - Training: 100%|██████████| 624/624 [00:00<00:00, 1010.11it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 9\n",
      "Training Loss: 0.1055\n",
      "Validation Loss: 0.1312\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7466\n",
      "  Hamming Accuracy: 0.9488\n",
      "  F1: 0.8773\n",
      "Early stopping triggered at epoch 9\n",
      "\n",
      "FOLD 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 1 - Training: 100%|██████████| 624/624 [00:00<00:00, 854.52it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 1\n",
      "Training Loss: 0.1992\n",
      "Validation Loss: 0.1476\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7159\n",
      "  Hamming Accuracy: 0.9410\n",
      "  F1: 0.8533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 2 - Training: 100%|██████████| 624/624 [00:00<00:00, 904.38it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 2\n",
      "Training Loss: 0.1435\n",
      "Validation Loss: 0.1401\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7266\n",
      "  Hamming Accuracy: 0.9433\n",
      "  F1: 0.8605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 3 - Training: 100%|██████████| 624/624 [00:00<00:00, 873.28it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 3\n",
      "Training Loss: 0.1339\n",
      "Validation Loss: 0.1353\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7428\n",
      "  Hamming Accuracy: 0.9464\n",
      "  F1: 0.8668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 4 - Training: 100%|██████████| 624/624 [00:00<00:00, 906.86it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 4\n",
      "Training Loss: 0.1269\n",
      "Validation Loss: 0.1355\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7404\n",
      "  Hamming Accuracy: 0.9459\n",
      "  F1: 0.8656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 5 - Training: 100%|██████████| 624/624 [00:00<00:00, 822.04it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 5\n",
      "Training Loss: 0.1220\n",
      "Validation Loss: 0.1326\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7400\n",
      "  Hamming Accuracy: 0.9471\n",
      "  F1: 0.8710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 6 - Training: 100%|██████████| 624/624 [00:00<00:00, 1015.36it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 6\n",
      "Training Loss: 0.1164\n",
      "Validation Loss: 0.1319\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7430\n",
      "  Hamming Accuracy: 0.9481\n",
      "  F1: 0.8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 7 - Training: 100%|██████████| 624/624 [00:00<00:00, 805.02it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 7\n",
      "Training Loss: 0.1133\n",
      "Validation Loss: 0.1304\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7466\n",
      "  Hamming Accuracy: 0.9486\n",
      "  F1: 0.8761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 8 - Training: 100%|██████████| 624/624 [00:00<00:00, 1005.65it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 8\n",
      "Training Loss: 0.1093\n",
      "Validation Loss: 0.1305\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7460\n",
      "  Hamming Accuracy: 0.9487\n",
      "  F1: 0.8752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 9 - Training: 100%|██████████| 624/624 [00:00<00:00, 936.13it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 9\n",
      "Training Loss: 0.1058\n",
      "Validation Loss: 0.1326\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7416\n",
      "  Hamming Accuracy: 0.9479\n",
      "  F1: 0.8766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 10 - Training: 100%|██████████| 624/624 [00:00<00:00, 777.43it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 10\n",
      "Training Loss: 0.1020\n",
      "Validation Loss: 0.1392\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7396\n",
      "  Hamming Accuracy: 0.9468\n",
      "  F1: 0.8684\n",
      "Early stopping triggered at epoch 10\n",
      "\n",
      "FOLD 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 1 - Training: 100%|██████████| 624/624 [00:00<00:00, 1033.00it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 1\n",
      "Training Loss: 0.2030\n",
      "Validation Loss: 0.1471\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7115\n",
      "  Hamming Accuracy: 0.9406\n",
      "  F1: 0.8507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 2 - Training: 100%|██████████| 624/624 [00:00<00:00, 862.80it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 2\n",
      "Training Loss: 0.1448\n",
      "Validation Loss: 0.1372\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7336\n",
      "  Hamming Accuracy: 0.9452\n",
      "  F1: 0.8643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 3 - Training: 100%|██████████| 624/624 [00:00<00:00, 668.28it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 3\n",
      "Training Loss: 0.1334\n",
      "Validation Loss: 0.1324\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7438\n",
      "  Hamming Accuracy: 0.9475\n",
      "  F1: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 4 - Training: 100%|██████████| 624/624 [00:00<00:00, 889.83it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 4\n",
      "Training Loss: 0.1267\n",
      "Validation Loss: 0.1313\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7508\n",
      "  Hamming Accuracy: 0.9486\n",
      "  F1: 0.8744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 5 - Training: 100%|██████████| 624/624 [00:00<00:00, 835.42it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 5\n",
      "Training Loss: 0.1220\n",
      "Validation Loss: 0.1354\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7468\n",
      "  Hamming Accuracy: 0.9471\n",
      "  F1: 0.8710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 6 - Training: 100%|██████████| 624/624 [00:00<00:00, 953.56it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 6\n",
      "Training Loss: 0.1169\n",
      "Validation Loss: 0.1285\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7528\n",
      "  Hamming Accuracy: 0.9500\n",
      "  F1: 0.8773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 7 - Training: 100%|██████████| 624/624 [00:00<00:00, 800.87it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 7\n",
      "Training Loss: 0.1129\n",
      "Validation Loss: 0.1291\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7510\n",
      "  Hamming Accuracy: 0.9496\n",
      "  F1: 0.8767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 8 - Training: 100%|██████████| 624/624 [00:00<00:00, 968.78it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 8\n",
      "Training Loss: 0.1087\n",
      "Validation Loss: 0.1296\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7464\n",
      "  Hamming Accuracy: 0.9494\n",
      "  F1: 0.8789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 9 - Training: 100%|██████████| 624/624 [00:00<00:00, 1024.16it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 9\n",
      "Training Loss: 0.1054\n",
      "Validation Loss: 0.1316\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7524\n",
      "  Hamming Accuracy: 0.9499\n",
      "  F1: 0.8783\n",
      "Early stopping triggered at epoch 9\n",
      "\n",
      "FOLD 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 1 - Training: 100%|██████████| 624/624 [00:00<00:00, 881.66it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 1\n",
      "Training Loss: 0.2006\n",
      "Validation Loss: 0.1481\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7179\n",
      "  Hamming Accuracy: 0.9404\n",
      "  F1: 0.8504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 2 - Training: 100%|██████████| 624/624 [00:00<00:00, 920.19it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 2\n",
      "Training Loss: 0.1436\n",
      "Validation Loss: 0.1414\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7310\n",
      "  Hamming Accuracy: 0.9440\n",
      "  F1: 0.8614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 3 - Training: 100%|██████████| 624/624 [00:00<00:00, 837.02it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 3\n",
      "Training Loss: 0.1331\n",
      "Validation Loss: 0.1439\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7272\n",
      "  Hamming Accuracy: 0.9425\n",
      "  F1: 0.8583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 4 - Training: 100%|██████████| 624/624 [00:00<00:00, 977.07it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 4\n",
      "Training Loss: 0.1264\n",
      "Validation Loss: 0.1343\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7334\n",
      "  Hamming Accuracy: 0.9454\n",
      "  F1: 0.8635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 5 - Training: 100%|██████████| 624/624 [00:00<00:00, 753.33it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 5\n",
      "Training Loss: 0.1212\n",
      "Validation Loss: 0.1338\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7430\n",
      "  Hamming Accuracy: 0.9472\n",
      "  F1: 0.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 6 - Training: 100%|██████████| 624/624 [00:00<00:00, 865.91it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 6\n",
      "Training Loss: 0.1170\n",
      "Validation Loss: 0.1322\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7448\n",
      "  Hamming Accuracy: 0.9480\n",
      "  F1: 0.8746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 7 - Training: 100%|██████████| 624/624 [00:00<00:00, 941.45it/s] \n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 7\n",
      "Training Loss: 0.1122\n",
      "Validation Loss: 0.1316\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7456\n",
      "  Hamming Accuracy: 0.9473\n",
      "  F1: 0.8702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 8 - Training: 100%|██████████| 624/624 [00:00<00:00, 780.49it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 8\n",
      "Training Loss: 0.1089\n",
      "Validation Loss: 0.1324\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7436\n",
      "  Hamming Accuracy: 0.9475\n",
      "  F1: 0.8731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 9 - Training: 100%|██████████| 624/624 [00:00<00:00, 631.60it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 9\n",
      "Training Loss: 0.1048\n",
      "Validation Loss: 0.1381\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7402\n",
      "  Hamming Accuracy: 0.9470\n",
      "  F1: 0.8740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 10 - Training: 100%|██████████| 624/624 [00:00<00:00, 808.77it/s]\n",
      "/lustre/home/rahmanr12/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 10\n",
      "Training Loss: 0.1016\n",
      "Validation Loss: 0.1351\n",
      "Validation Metrics:\n",
      "  Exact Match Accuracy: 0.7454\n",
      "  Hamming Accuracy: 0.9483\n",
      "  F1: 0.8760\n",
      "Early stopping triggered at epoch 10\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2585204/330386721.py:610: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'best_model_fold_{best_fold+1}.pt'))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_model_fold_1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-mpnet-base-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 610\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    608\u001b[0m model \u001b[38;5;241m=\u001b[39m TopicClassifier(input_dim\u001b[38;5;241m=\u001b[39membedding_dim)\n\u001b[1;32m    609\u001b[0m \u001b[38;5;66;03m# Use the tracked best_fold instead of computing it\u001b[39;00m\n\u001b[0;32m--> 610\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_fold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_fold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    611\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    614\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_model_fold_1.pt'"
     ]
    }
   ],
   "source": [
    "run('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c418d3-8b71-4469-a290-4a9e7884ff2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
